{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import TweepError\n",
    "from textblob import TextBlob\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from gensim import corpora, models\n",
    "import numpy as np\n",
    "import json\n",
    "import operator\n",
    "import time\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = \"xzSxeuO5GSQgZs3NwVIQrpF0S\"\n",
    "consumer_secret = \"w4aRpCMP6sA24eZdU5HHYH2SZrPSPIgFZSTCHhSjdDN8Eusg0r\"\n",
    "access_token = \"30304291-bQzWBtaXNBe4FG0L9Nbcq14p7WGYJjl84liBvT3YC\"\n",
    "access_token_secret = \"WUtyRsPtsZnmDY99t7dSxnPSqDxpfwitplYzZwGBfFFPa\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers\n",
      "1258\n",
      "Sleeping for 15 minutes\n",
      "2015\n",
      "Sleeping for 15 minutes\n",
      "Wakanda\n",
      "Marvel\n"
     ]
    }
   ],
   "source": [
    "input_queries = ['Avengers','Wakanda','Marvel']\n",
    "download_tweet_count = 4000 \n",
    "tweetsPerQry = 200\n",
    "sinceId = None\n",
    "max_id = -1L\n",
    "\n",
    "dataset = defaultdict(list)\n",
    "for input_query in input_queries:\n",
    "    print(input_query)\n",
    "    counter = 0\n",
    "    while counter < download_tweet_count:\n",
    "       try:\n",
    "           if (max_id <= 0):\n",
    "               if (not sinceId):\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry)\n",
    "               else:\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, since_id=sinceId)\n",
    "           else:\n",
    "               if (not sinceId):\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, max_id=str(max_id - 1))\n",
    "               else:\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, max_id=str(max_id - 1), since_id=sinceId)\n",
    "           for tweet in new_tweets:\n",
    "               dataset['topic'].append(input_query)\n",
    "               dataset['id'].append(tweet.id)\n",
    "               # user related information\n",
    "               dataset['username'].append(tweet.author.screen_name)\n",
    "               dataset['name'].append(tweet.author.name)\n",
    "               dataset['user_followers_count'].append(tweet.author.followers_count)\n",
    "               dataset['user_friends_count'].append(tweet.author.friends_count)\n",
    "               # tweet related information\n",
    "               dataset['text'].append(tweet.text)\n",
    "               dataset['created_at'].append(tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "               dataset['favorite_count'].append(tweet.favorite_count)\n",
    "               dataset['retweet_count'].append(tweet.retweet_count)\n",
    "               # some extracted data from tweet\n",
    "               dataset['hashtags'].append(','.join([ht['text'] for ht in tweet.entities['hashtags']]))\n",
    "               dataset['mentioned_urls'].append(','.join([url['url'] for url in tweet.entities['urls']]))\n",
    "               dataset['mentioned_user_ids'].append(','.join([mention['id_str'] for mention in tweet.entities['user_mentions']]))\n",
    "               dataset['mentioned_user_names'].append(','.join([mention['screen_name'] for mention in tweet.entities['user_mentions']]))\n",
    "           counter +=len(new_tweets)\n",
    "           max_id = new_tweets[0].id\n",
    "           if counter == download_tweet_count: break\n",
    "       except TweepError:\n",
    "           print(len(dataset['id']))\n",
    "           print('Sleeping for 15 minutes')\n",
    "           time.sleep(15*60) # sleep for 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tweet objects to JSON please wait...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "file = open('Homework4Tweets.json', 'wb') \n",
    "print \"Writing tweet objects to JSON please wait...\"\n",
    "for status in new_tweets:\n",
    "    json.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "    \n",
    "#close the file\n",
    "print \"Done\"\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>2018-04-08 03:47:49</td>\n",
       "      <td>New Trailer! Wakanda is here baby! üôÖüèΩ‚Äç‚ôÄÔ∏è Mar...</td>\n",
       "      <td></td>\n",
       "      <td>MixedGirlMane</td>\n",
       "      <td>425</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>2018-04-08 03:21:19</td>\n",
       "      <td>RT @netheadww: Oh man... 19 days to go and the...</td>\n",
       "      <td></td>\n",
       "      <td>DynamoCooligan</td>\n",
       "      <td>3585</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>2018-04-08 03:19:31</td>\n",
       "      <td>„Çª„ÉÉ„ÉàË®™ÂïèË®ò„ÇΩ„Éº„Çπ\\nhttps://t.co/xgj7cOTDTt\\n\\nhttps://...</td>\n",
       "      <td></td>\n",
       "      <td>onemuseb</td>\n",
       "      <td>63</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>2018-04-08 03:17:23</td>\n",
       "      <td>RT @DEADLINE: ‚ÄòInfinity War‚Äô: Wakanda Takes Ce...</td>\n",
       "      <td></td>\n",
       "      <td>dviola56</td>\n",
       "      <td>989</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>2018-04-08 03:03:22</td>\n",
       "      <td>RT @DEADLINE: ‚ÄòInfinity War‚Äô: Wakanda Takes Ce...</td>\n",
       "      <td></td>\n",
       "      <td>lcm1pen</td>\n",
       "      <td>3327</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "9039  2018-04-08 03:47:49  New Trailer! Wakanda is here baby! üôÖüèΩ‚Äç‚ôÄÔ∏è Mar...   \n",
       "9040  2018-04-08 03:21:19  RT @netheadww: Oh man... 19 days to go and the...   \n",
       "9041  2018-04-08 03:19:31  „Çª„ÉÉ„ÉàË®™ÂïèË®ò„ÇΩ„Éº„Çπ\\nhttps://t.co/xgj7cOTDTt\\n\\nhttps://...   \n",
       "9042  2018-04-08 03:17:23  RT @DEADLINE: ‚ÄòInfinity War‚Äô: Wakanda Takes Ce...   \n",
       "9043  2018-04-08 03:03:22  RT @DEADLINE: ‚ÄòInfinity War‚Äô: Wakanda Takes Ce...   \n",
       "\n",
       "     hashtags        username  user_followers_count   topic  \n",
       "9039            MixedGirlMane                   425  Marvel  \n",
       "9040           DynamoCooligan                  3585  Marvel  \n",
       "9041                 onemuseb                    63  Marvel  \n",
       "9042                 dviola56                   989  Marvel  \n",
       "9043                  lcm1pen                  3327  Marvel  "
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe for entire dataset\n",
    "dt = pd.DataFrame.from_dict(dataset)\n",
    "dt[['created_at','text','hashtags','username','user_followers_count','topic']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4JAkdTE4JEldDA5JUheDQ5LU5f8DIG2ilvzTDnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1175c46d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "filtered_dt = dt[dt['retweet_count'] <= np.percentile(dt['retweet_count'],99)]\n",
    "filtered_dt['retweet_count'].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is anyone else rewatching the Marvel movies getting ready for Avengers: Infinity Wars next week? #InfinityWars‚Ä¶ https://t.co/7MTMvU4Z78\n",
      "Sentiment(polarity=0.1, subjectivity=0.25)\n",
      "----------\n",
      "RT @MarvelUK: Psyched to return to Black Panther's Kingdom in Avengers: #InfinityWar? Wakanda forever! https://t.co/tDuNHDt962\n",
      "Sentiment(polarity=-0.20833333333333331, subjectivity=0.43333333333333335)\n",
      "----------\n",
      "MARVEL MONDAY! The King is here! #BlackPanther #AvengersInfinityWar #Wakanda Forever https://t.co/sYvCVL2ZTV\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @MSTS2307: More few days to go for #AvengersInfinityWar ‚ú®‚ú®\n",
      "#CaptainAmerica @CaptainAmerica\n",
      "@Marvel @MarvelStudios @MarvelSupport #Marvel‚Ä¶\n",
      "Sentiment(polarity=0.15, subjectivity=0.3)\n",
      "----------\n",
      "https://t.co/HzgJwcUkix #madeinnigeria #global #dealafriq #nigeria #ghana #senegal #africa #madeinafrica #avengers‚Ä¶ https://t.co/TORAItpTFG\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "@MarvelStudios @Avengers DESTINY ARRIVES IN WAKANDA! #InfinityWar #Marvel #BlackPanther #Thanos #IronMan #Hulk‚Ä¶ https://t.co/zdfxeewuTx\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "üòÇüòÇüòÇüòÇüòÇ #infinitwars #apocolypse #avengers #marvel #wakanda #blackpanther #thor #ironman #hulk‚Ä¶ https://t.co/4sjNHf0mpR\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "Cap made it to Wakanda, so X him out, gotta be Loki. RT @RealScreenGeek: Major Marvel Character Dies At The Beginni‚Ä¶ https://t.co/2soOcFST2s\n",
      "Sentiment(polarity=0.0625, subjectivity=0.5)\n",
      "----------\n",
      "More few days to go for #AvengersInfinityWar ‚ú®‚ú®\n",
      "#CaptainAmerica @CaptainAmerica\n",
      "@Marvel @MarvelStudios‚Ä¶ https://t.co/DOUZ16oXti\n",
      "Sentiment(polarity=0.15, subjectivity=0.3)\n",
      "----------\n",
      "@JerrellZod Yes. Avengers Infinity War unites King T'Challa and the Wakandas with Captain America, and Wakanda open‚Ä¶ https://t.co/Y1RPoCevZ7\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "A still from the Black Panther short, that I shot.\n",
      "Produced/Directed by @thejimlogan\n",
      "Black Panther Stunt Double:‚Ä¶ https://t.co/OfruIheEdt\n",
      "Sentiment(polarity=-0.1111111111111111, subjectivity=0.3888888888888889)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @comicbookstore_: \"Your Saviour is here! Did you miss me?\"\n",
      "Loki is the best! Do you think he's gonna die in #Avengers #InfinityWar ?\n",
      "\n",
      "#l‚Ä¶\n",
      "Sentiment(polarity=1.0, subjectivity=0.3)\n",
      "----------\n",
      "\"Your Saviour is here! Did you miss me?\"\n",
      "Loki is the best! Do you think he's gonna die in #Avengers #InfinityWar ?‚Ä¶ https://t.co/TgGC1yoUC7\n",
      "Sentiment(polarity=1.0, subjectivity=0.3)\n",
      "----------\n",
      "RT @Beyond_The_3D: Wakanda Forever!\n",
      "\n",
      "Hope everyone had a good weekend! I had a dream last night about watching Avengers Infinity War can't‚Ä¶\n",
      "Sentiment(polarity=0.4375, subjectivity=0.33333333333333337)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TextBlob Sentiment Analysis - Entire Dataset\n",
    "\n",
    "# perform sentiment analysis on each tweet\n",
    "# -1 < polarity < 1 (negativity vs positivity (sentiment))\n",
    "# 0 < subjectivity < 1 (factual vs opinion)\n",
    "for tweet in dt['text'].head(20):\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print (analysis.sentiment)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senitments Breakdown - Entire Dataset:\n",
      "Percentage of Positive Tweets: 60%\n",
      "Percentage of Neutral Tweets: 27%\n",
      "Percentage of Negative Tweets: 11%\n"
     ]
    }
   ],
   "source": [
    "dt['SA'] = ([TextBlob(tweet).polarity for tweet in dataset['text']])\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(dataset['text']) if dt['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(dataset['text']) if dt['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(dataset['text']) if dt['SA'][index] < 0]\n",
    "\n",
    "print(\"Senitments Breakdown - Entire Dataset:\")\n",
    "print(\"Percentage of Positive Tweets: {}%\".format(len(pos_tweets)*100/len(dataset['text'])))\n",
    "print(\"Percentage of Neutral Tweets: {}%\".format(len(neu_tweets)*100/len(dataset['text'])))\n",
    "print(\"Percentage of Negative Tweets: {}%\".format(len(neg_tweets)*100/len(dataset['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 4428), (u'avengers', 2390), (u'BlackPanther', 1923), (u'marvel', 1917), (u'cosplay', 1466)]\n"
     ]
    }
   ],
   "source": [
    "#Top 5 hashtags for entire dataset\n",
    "hashtag_counter = Counter()\n",
    "for hts in dt['hashtags'].values:\n",
    "    hts = hts.split(',')\n",
    "    hashtag_counter.update(hts)\n",
    "    \n",
    "sorted_cntr = sorted(hashtag_counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(sorted_cntr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis Topic #1 - \"Avengers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-17 01:27:09</td>\n",
       "      <td>Is anyone else rewatching the Marvel movies ge...</td>\n",
       "      <td>InfinityWars</td>\n",
       "      <td>willocassidy</td>\n",
       "      <td>29</td>\n",
       "      <td>Avengers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-16 23:14:49</td>\n",
       "      <td>RT @MarvelUK: Psyched to return to Black Panth...</td>\n",
       "      <td>InfinityWar</td>\n",
       "      <td>1025_marvel</td>\n",
       "      <td>805</td>\n",
       "      <td>Avengers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2018-04-17 01:27:09  Is anyone else rewatching the Marvel movies ge...   \n",
       "1  2018-04-16 23:14:49  RT @MarvelUK: Psyched to return to Black Panth...   \n",
       "\n",
       "       hashtags      username  user_followers_count     topic  \n",
       "0  InfinityWars  willocassidy                    29  Avengers  \n",
       "1   InfinityWar   1025_marvel                   805  Avengers  "
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset for 'Avengers' topic\n",
    "filtered_AvengersDt = dt.loc[dt['topic'] == 'Avengers']\n",
    "filtered_AvengersDt[['created_at','text','hashtags','username','user_followers_count','topic']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is anyone else rewatching the Marvel movies getting ready for Avengers: Infinity Wars next week? #InfinityWars‚Ä¶ https://t.co/7MTMvU4Z78\n",
      "Sentiment(polarity=0.1, subjectivity=0.25)\n",
      "----------\n",
      "RT @MarvelUK: Psyched to return to Black Panther's Kingdom in Avengers: #InfinityWar? Wakanda forever! https://t.co/tDuNHDt962\n",
      "Sentiment(polarity=-0.20833333333333331, subjectivity=0.43333333333333335)\n",
      "----------\n",
      "MARVEL MONDAY! The King is here! #BlackPanther #AvengersInfinityWar #Wakanda Forever https://t.co/sYvCVL2ZTV\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @MSTS2307: More few days to go for #AvengersInfinityWar ‚ú®‚ú®\n",
      "#CaptainAmerica @CaptainAmerica\n",
      "@Marvel @MarvelStudios @MarvelSupport #Marvel‚Ä¶\n",
      "Sentiment(polarity=0.15, subjectivity=0.3)\n",
      "----------\n",
      "https://t.co/HzgJwcUkix #madeinnigeria #global #dealafriq #nigeria #ghana #senegal #africa #madeinafrica #avengers‚Ä¶ https://t.co/TORAItpTFG\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "@MarvelStudios @Avengers DESTINY ARRIVES IN WAKANDA! #InfinityWar #Marvel #BlackPanther #Thanos #IronMan #Hulk‚Ä¶ https://t.co/zdfxeewuTx\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TextBlob Sentiment Analysis - \"Avengers\" Dataset\n",
    "for tweet in filtered_AvengersDt['text'].head(10):\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print(analysis.sentiment)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senitments Breakdown - Avengers Dataset:\n",
      "Percentage of Positive Tweets: 71%\n",
      "Percentage of Neutral Tweets: 16%\n",
      "Percentage of Negative Tweets: 12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinahill/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filtered_AvengersDt['SA'] = ([TextBlob(tweet).polarity for tweet in filtered_AvengersDt['text']])\n",
    "\n",
    "pos_tweets_A = [ tweet for index, tweet in enumerate(filtered_AvengersDt['text']) if filtered_AvengersDt['SA'][index] > 0]\n",
    "neu_tweets_A = [ tweet for index, tweet in enumerate(filtered_AvengersDt['text']) if filtered_AvengersDt['SA'][index] == 0]\n",
    "neg_tweets_A = [ tweet for index, tweet in enumerate(filtered_AvengersDt['text']) if filtered_AvengersDt['SA'][index] < 0]\n",
    "\n",
    "print(\"Senitments Breakdown - Avengers Dataset:\")\n",
    "print(\"Percentage of Positive Tweets: {}%\".format(len(pos_tweets_A)*100/len(filtered_AvengersDt['text'])))\n",
    "print(\"Percentage of Neutral Tweets: {}%\".format(len(neu_tweets_A)*100/len(filtered_AvengersDt['text'])))\n",
    "print(\"Percentage of Negative Tweets: {}%\".format(len(neg_tweets_A)*100/len(filtered_AvengersDt['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 2037), (u'avengers', 327), (u'AvengersInfinityWar', 240), (u'fanart', 214), (u'poster', 204)]\n"
     ]
    }
   ],
   "source": [
    "#Top  hashtags for \"Avengers\" dataset\n",
    "hashtag_counter = Counter()\n",
    "for hts in filtered_AvengersDt['hashtags'].values:\n",
    "    hts = hts.split(',')\n",
    "    hashtag_counter.update(hts)\n",
    "    \n",
    "sorted_cntr = sorted(hashtag_counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(sorted_cntr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis Topic #2 - \"Wakanda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2018-04-14 18:08:00</td>\n",
       "      <td>RT @BoxOfficeBrief: Avengers Infinity War Give...</td>\n",
       "      <td></td>\n",
       "      <td>Filmgirl88</td>\n",
       "      <td>110</td>\n",
       "      <td>Wakanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>2018-04-14 18:07:50</td>\n",
       "      <td>RT @BoxOfficeBrief: Avengers Infinity War Give...</td>\n",
       "      <td></td>\n",
       "      <td>Thefbenews</td>\n",
       "      <td>1</td>\n",
       "      <td>Wakanda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "3000  2018-04-14 18:08:00  RT @BoxOfficeBrief: Avengers Infinity War Give...   \n",
       "3001  2018-04-14 18:07:50  RT @BoxOfficeBrief: Avengers Infinity War Give...   \n",
       "\n",
       "     hashtags    username  user_followers_count    topic  \n",
       "3000           Filmgirl88                   110  Wakanda  \n",
       "3001           Thefbenews                     1  Wakanda  "
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset for 'Wakanda' topic\n",
    "filtered_WakandaDt = dt.loc[dt['topic'] == 'Wakanda']\n",
    "filtered_WakandaDt[['created_at','text','hashtags','username','user_followers_count','topic']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infini‚Ä¶ https://t.co/8hD3ESv9rz\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "#shuriblackpanther #avengers #infinityguantlet #mcu #marvel @ Wakanda https://t.co/eZgOfuMnnh\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @comicbookstore_: Kamehamehaa DormamuüòÇ\n",
      "Fan Art - Dr. Strange\n",
      "Checkout our dope collection at https://t.co/qOB9xHc1lR\n",
      "\n",
      "#poster #fanart #c‚Ä¶\n",
      "Sentiment(polarity=-0.05, subjectivity=0.15)\n",
      "----------\n",
      "#Jewelry #Fashion Buy Now: $32.98 BLACK PANTHER Wakanda Wu Tang Style Hoodie Marvel Avengers Adult &amp; Youth‚Ä¶ https://t.co/5uVt9NDr52\n",
      "Sentiment(polarity=-0.033333333333333326, subjectivity=0.3666666666666667)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TextBlob Sentiment Analysis - \"Wakanda\" Dataset\n",
    "for tweet in filtered_WakandaDt['text'].head(10):\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print(analysis.sentiment)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinahill/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filtered_WakandaDt['SA'] = ([TextBlob(tweet).polarity for tweet in filtered_WakandaDt['text']])\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(filtered_WakandaDt['text']) if filtered_WakandaDt['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(filtered_WakandaDt['text']) if filtered_WakandaDt['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(filtered_WakandaDt['text']) if filtered_WakandaDt['SA'][index] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 2609), (u'BlackPanther', 1856), (u'marvel', 746), (u'InfinityWar', 709), (u'Avengers', 665)]\n"
     ]
    }
   ],
   "source": [
    "#Top 5 hashtags for \"Wakanda\" dataset\n",
    "hashtag_counter = Counter()\n",
    "for hts in filtered_WakandaDt['hashtags'].values:\n",
    "    hts = hts.split(',')\n",
    "    hashtag_counter.update(hts)\n",
    "    \n",
    "sorted_cntr = sorted(hashtag_counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(sorted_cntr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis Topic #3 - \"Marvel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>2018-04-10 12:25:32</td>\n",
       "      <td>RT @TheDisneyBlog: Black Panther and Wakanda r...</td>\n",
       "      <td></td>\n",
       "      <td>BeasleyDenzel</td>\n",
       "      <td>176</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>2018-04-10 12:11:03</td>\n",
       "      <td>Black Panther and Wakanda really show up in la...</td>\n",
       "      <td></td>\n",
       "      <td>TheDisneyBlog</td>\n",
       "      <td>116734</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at                                               text  \\\n",
       "6033  2018-04-10 12:25:32  RT @TheDisneyBlog: Black Panther and Wakanda r...   \n",
       "6034  2018-04-10 12:11:03  Black Panther and Wakanda really show up in la...   \n",
       "\n",
       "     hashtags       username  user_followers_count   topic  \n",
       "6033           BeasleyDenzel                   176  Marvel  \n",
       "6034           TheDisneyBlog                116734  Marvel  "
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset for 'Marvel' topic\n",
    "filtered_MarvelDt = dt[dt['topic'] == 'Marvel']\n",
    "filtered_MarvelDt[['created_at','text','hashtags','username','user_followers_count','topic']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TheDisneyBlog: Black Panther and Wakanda really show up in latest TV trailer for Avengers: Infinity War. Plus O‚Ä¶ https://t.co/Q2ouCUddpE\n",
      "Sentiment(polarity=0.17777777777777778, subjectivity=0.5111111111111111)\n",
      "----------\n",
      "Black Panther and Wakanda really show up in latest TV trailer for Avengers: Infinity War. Plus Okoye has one of the‚Ä¶ https://t.co/3MCN3bujz2\n",
      "Sentiment(polarity=0.17777777777777778, subjectivity=0.5111111111111111)\n",
      "----------\n",
      "Don‚Äôt freeze. We‚Äôre just 2 months away until Black Panther and the rest of the Avengers descend upon‚Ä¶ https://t.co/FsD6xT56Ds\n",
      "Sentiment(polarity=-0.16666666666666666, subjectivity=0.43333333333333335)\n",
      "----------\n",
      "\"Wakanda per sempre\"? Thanos non sembra del loro stesso avviso. Quanto siete in fibrillazione per il nuovo cinecomi‚Ä¶ https://t.co/pCRk61UjVT\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "#blackpanther¬† #ironman¬† #spiderman¬† #captainamerica¬† #thor¬†#GuardiansOfTheGalaxy #Hulk #StarLord #Okoye #Avengers‚Ä¶ https://t.co/dEfmCNo3Sg\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "Penis Parker comes back to Marvel - as WHINE+SPACE look back at #SpidermanHomecoming!\n",
      "\n",
      "#spiderman #SpiderManPS4‚Ä¶ https://t.co/MuIxKTrG6L\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "@ruey1010 I'm looking forward to Avengers Infinity War with  Black Panther, side by side with Captain America in Wa‚Ä¶ https://t.co/h4zdgSz7tM\n",
      "Sentiment(polarity=-0.16666666666666666, subjectivity=0.43333333333333335)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 of the new Avengers Infinity War ch‚Ä¶\n",
      "Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453)\n",
      "----------\n",
      "RT @screencrushnews: You can pinpoint the exact moment when Marvel figured out they should be marketing ‚ÄòInfinity War‚Äô as ‚ÄòBlack Panther 1.‚Ä¶\n",
      "Sentiment(polarity=0.04166666666666667, subjectivity=0.3416666666666667)\n",
      "----------\n",
      "RT @screencrushnews: You can pinpoint the exact moment when Marvel figured out they should be marketing ‚ÄòInfinity War‚Äô as ‚ÄòBlack Panther 1.‚Ä¶\n",
      "Sentiment(polarity=0.04166666666666667, subjectivity=0.3416666666666667)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TextBlob Sentiment Analysis - \"Marvel\" Dataset\n",
    "# perform sentiment analysis on each tweet\n",
    "# -1 < polarity < 1 (negativity vs positivity (sentiment))\n",
    "# 0 < subjectivity < 1 (factual vs opinion)\n",
    "for tweet in filtered_MarvelDt['text'].head(10):\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print(analysis.sentiment)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinahill/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filtered_MarvelDt['SA'] = ([TextBlob(tweet).polarity for tweet in filtered_MarvelDt['text']])\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(filtered_MarvelDt['text']) if filtered_MarvelDt['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(filtered_MarvelDt['text']) if filtered_MarvelDt['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(filtered_MarvelDt['text']) if filtered_MarvelDt['SA'][index] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'BlackPanther', 1820), (u'InfinityWar', 1711), ('', 1638), (u'Avengers', 815), (u'AvengersInfinityWar', 230)]\n"
     ]
    }
   ],
   "source": [
    "#Top 20 hashtags for \"Marvel\" dataset\n",
    "hashtag_counter = Counter()\n",
    "for hts in filtered_MarvelDt['hashtags'].values:\n",
    "    hts = hts.split(',')\n",
    "    hashtag_counter.update(hts)\n",
    "    \n",
    "sorted_cntr = sorted(hashtag_counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(sorted_cntr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Analysis on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process only the texts of tweets for entire dataset\n",
    "all_docs = dt['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Propose pre-processing chain to consider aspects of English language\n",
    "import re\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'the', u'king', u'is', u'here', u'blackpanther', u'avengersinfinitywar', u'wakanda', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization using TweetTokenizer for entire dataset\n",
    "exclude = set(string.punctuation)\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'king', u'blackpanther', u'avengersinfinitywar', u'wakanda', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "#Stop-word Removal for entire dataset\n",
    "sws = set(stopwords.words('english'))\n",
    "sws.add('rt') # Tweet specific stop-words\n",
    "sws_removed = []\n",
    "for j,sent in enumerate(tokenized):\n",
    "    sws_removed.append([i for i in sent if i not in sws])\n",
    "print(sws_removed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1), (16, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Gensim Library\n",
    "dictionary = corpora.Dictionary(sws_removed)\n",
    "corpus = [dictionary.doc2bow(text) for text in sws_removed]\n",
    "print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LDA Model\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.072*\"photo\" + 0.070*\"jackfluck\" + 0.066*\"avengers\"'), (1, u'0.066*\"wakanda\" + 0.049*\"marvel\" + 0.043*\"war\"'), (2, u'0.066*\"\\u2026\" + 0.057*\"avengers\" + 0.055*\"marvel\"')]\n"
     ]
    }
   ],
   "source": [
    "#Examine Results\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Of Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers\n",
      "Wakanda\n",
      "6825\n",
      "Sleeping for 15 minutes\n",
      "Marvel\n"
     ]
    }
   ],
   "source": [
    "input_queries = ['Avengers','Wakanda','Marvel']\n",
    "download_tweet_count = 8000 \n",
    "tweetsPerQry = 200\n",
    "sinceId = None\n",
    "max_id = -1L\n",
    "\n",
    "dataset_1 = defaultdict(list)\n",
    "for input_query in input_queries:\n",
    "    print(input_query)\n",
    "    counter = 0\n",
    "    while counter < download_tweet_count:\n",
    "       try:\n",
    "           if (max_id <= 0):\n",
    "               if (not sinceId):\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry)\n",
    "               else:\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, since_id=sinceId)\n",
    "           else:\n",
    "               if (not sinceId):\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, max_id=str(max_id - 1))\n",
    "               else:\n",
    "                   new_tweets = api.search(q=input_queries, count=tweetsPerQry, max_id=str(max_id - 1), since_id=sinceId)\n",
    "           for tweet in new_tweets:\n",
    "               dataset_1['topic'].append(input_query)\n",
    "               dataset_1['id'].append(tweet.id)\n",
    "               # user related information\n",
    "               dataset_1['username'].append(tweet.author.screen_name)\n",
    "               dataset_1['name'].append(tweet.author.name)\n",
    "               dataset_1['user_followers_count'].append(tweet.author.followers_count)\n",
    "               dataset_1['user_friends_count'].append(tweet.author.friends_count)\n",
    "               # tweet related information\n",
    "               dataset_1['text'].append(tweet.text)\n",
    "               dataset_1['created_at'].append(tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "               dataset_1['favorite_count'].append(tweet.favorite_count)\n",
    "               dataset_1['retweet_count'].append(tweet.retweet_count)\n",
    "               # some extracted data from tweet\n",
    "               dataset_1['hashtags'].append(','.join([ht['text'] for ht in tweet.entities['hashtags']]))\n",
    "               dataset_1['mentioned_urls'].append(','.join([url['url'] for url in tweet.entities['urls']]))\n",
    "               dataset_1['mentioned_user_ids'].append(','.join([mention['id_str'] for mention in tweet.entities['user_mentions']]))\n",
    "               dataset_1['mentioned_user_names'].append(','.join([mention['screen_name'] for mention in tweet.entities['user_mentions']]))\n",
    "           counter +=len(new_tweets)\n",
    "           max_id = new_tweets[0].id\n",
    "           if counter == download_tweet_count: break\n",
    "       except TweepError:\n",
    "           print(len(dataset_1['id']))\n",
    "           print('Sleeping for 15 minutes')\n",
    "           time.sleep(15*60) # sleep for 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for entire dataset\n",
    "dt_1 = pd.DataFrame.from_dict(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @MarvelUK: Psyched to return to Black Panther's Kingdom in Avengers: #InfinityWar? Wakanda forever! https://t.co/tDuNHDt962\n",
      "Sentiment(polarity=-0.20833333333333331, subjectivity=0.43333333333333335)\n",
      "----------\n",
      "MARVEL MONDAY! The King is here! #BlackPanther #AvengersInfinityWar #Wakanda Forever https://t.co/sYvCVL2ZTV\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @MSTS2307: More few days to go for #AvengersInfinityWar ‚ú®‚ú®\n",
      "#CaptainAmerica @CaptainAmerica\n",
      "@Marvel @MarvelStudios @MarvelSupport #Marvel‚Ä¶\n",
      "Sentiment(polarity=0.15, subjectivity=0.3)\n",
      "----------\n",
      "https://t.co/HzgJwcUkix #madeinnigeria #global #dealafriq #nigeria #ghana #senegal #africa #madeinafrica #avengers‚Ä¶ https://t.co/TORAItpTFG\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "@MarvelStudios @Avengers DESTINY ARRIVES IN WAKANDA! #InfinityWar #Marvel #BlackPanther #Thanos #IronMan #Hulk‚Ä¶ https://t.co/zdfxeewuTx\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "üòÇüòÇüòÇüòÇüòÇ #infinitwars #apocolypse #avengers #marvel #wakanda #blackpanther #thor #ironman #hulk‚Ä¶ https://t.co/4sjNHf0mpR\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "Cap made it to Wakanda, so X him out, gotta be Loki. RT @RealScreenGeek: Major Marvel Character Dies At The Beginni‚Ä¶ https://t.co/2soOcFST2s\n",
      "Sentiment(polarity=0.0625, subjectivity=0.5)\n",
      "----------\n",
      "More few days to go for #AvengersInfinityWar ‚ú®‚ú®\n",
      "#CaptainAmerica @CaptainAmerica\n",
      "@Marvel @MarvelStudios‚Ä¶ https://t.co/DOUZ16oXti\n",
      "Sentiment(polarity=0.15, subjectivity=0.3)\n",
      "----------\n",
      "@JerrellZod Yes. Avengers Infinity War unites King T'Challa and the Wakandas with Captain America, and Wakanda open‚Ä¶ https://t.co/Y1RPoCevZ7\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "----------\n",
      "A still from the Black Panther short, that I shot.\n",
      "Produced/Directed by @thejimlogan\n",
      "Black Panther Stunt Double:‚Ä¶ https://t.co/OfruIheEdt\n",
      "Sentiment(polarity=-0.1111111111111111, subjectivity=0.3888888888888889)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @BoxOfficeBrief: Avengers Infinity War Giveaway üö®! We are launching our new channel by giving away 4 MORE of the new Avengers Infinity W‚Ä¶\n",
      "Sentiment(polarity=0.25757575757575757, subjectivity=0.4696969696969697)\n",
      "----------\n",
      "RT @comicbookstore_: \"Your Saviour is here! Did you miss me?\"\n",
      "Loki is the best! Do you think he's gonna die in #Avengers #InfinityWar ?\n",
      "\n",
      "#l‚Ä¶\n",
      "Sentiment(polarity=1.0, subjectivity=0.3)\n",
      "----------\n",
      "\"Your Saviour is here! Did you miss me?\"\n",
      "Loki is the best! Do you think he's gonna die in #Avengers #InfinityWar ?‚Ä¶ https://t.co/TgGC1yoUC7\n",
      "Sentiment(polarity=1.0, subjectivity=0.3)\n",
      "----------\n",
      "RT @Beyond_The_3D: Wakanda Forever!\n",
      "\n",
      "Hope everyone had a good weekend! I had a dream last night about watching Avengers Infinity War can't‚Ä¶\n",
      "Sentiment(polarity=0.4375, subjectivity=0.33333333333333337)\n",
      "----------\n",
      "Wakanda Forever!\n",
      "\n",
      "Hope everyone had a good weekend! I had a dream last night about watching Avengers Infinity War c‚Ä¶ https://t.co/DjTFwW56V9\n",
      "Sentiment(polarity=0.4375, subjectivity=0.33333333333333337)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#TextBlob Sentiment Analysis - Entire Dataset\n",
    "# perform sentiment analysis on each tweet\n",
    "# -1 < polarity < 1 (negativity vs positivity (sentiment))\n",
    "# 0 < subjectivity < 1 (factual vs opinion)\n",
    "for tweet in dt_1['text'].head(20):\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print(analysis.sentiment)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senitments Breakdown - Entire Dataset:\n",
      "Percentage of Positive Tweets: 50%\n",
      "Percentage of Neutral Tweets: 40%\n",
      "Percentage of Negative Tweets: 9%\n"
     ]
    }
   ],
   "source": [
    "dataset_1['SA'] = ([TextBlob(tweet).polarity for tweet in dataset_1['text']])\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(dataset_1['text']) if dataset_1['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(dataset_1['text']) if dataset_1['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(dataset_1['text']) if dataset_1['SA'][index] < 0]\n",
    "\n",
    "print(\"Senitments Breakdown - Entire Dataset:\")\n",
    "print(\"Percentage of Positive Tweets: {}%\".format(len(pos_tweets)*100/len(dataset_1['text'])))\n",
    "print(\"Percentage of Neutral Tweets: {}%\".format(len(neu_tweets)*100/len(dataset_1['text'])))\n",
    "print(\"Percentage of Negative Tweets: {}%\".format(len(neg_tweets)*100/len(dataset_1['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARVEL MONDAY! The King is here! #BlackPanther #AvengersInfinityWar #Wakanda Forever https://t.co/sYvCVL2ZTV\n"
     ]
    }
   ],
   "source": [
    "# Process only the texts of tweets for entire dataset\n",
    "all_docs_1 = dt_1['text'].values\n",
    "print(all_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'rt', u'msts2307', u'more', u'few', u'days', u'to', u'go', u'for', u'avengersinfinitywar', u'\\u2728', u'\\u2728', u'captainamerica', u'captainamerica', u'marvel', u'marvelstudios', u'marvelsupport', u'marvel', u'\\u2026']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization using TweetTokenizer for entire dataset\n",
    "exclude = set(string.punctuation)\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs_1:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'msts2307', u'days', u'go', u'avengersinfinitywar', u'\\u2728', u'\\u2728', u'captainamerica', u'captainamerica', u'marvel', u'marvelstudios', u'marvelsupport', u'marvel', u'\\u2026']\n"
     ]
    }
   ],
   "source": [
    "#Stop-word Removal for entire dataset\n",
    "sws = set(stopwords.words('english'))\n",
    "sws.add('rt') # Tweet specific stop-words\n",
    "sws_removed = []\n",
    "for j,sent in enumerate(tokenized):\n",
    "    sws_removed.append([i for i in sent if i not in sws])\n",
    "print(sws_removed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1), (16, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Gensim Library\n",
    "dictionary = corpora.Dictionary(sws_removed)\n",
    "corpus = [dictionary.doc2bow(text) for text in sws_removed]\n",
    "print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LDA Model\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.078*\"marvel\" + 0.062*\"wakanda\" + 0.055*\"avengers\"'), (1, u'0.057*\"avengers\" + 0.053*\"wakanda\" + 0.046*\"de\"'), (2, u'0.047*\"\\ud83e\" + 0.047*\"\\udd17\" + 0.043*\"avengers\"')]\n"
     ]
    }
   ],
   "source": [
    "#Examine Results\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Results Without Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = dt['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'the', u'king', u'is', u'here', u'blackpanther', u'avengersinfinitywar', u'wakanda', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation)\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 1), (9, 1), (14, 1), (19, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Gensim Library\n",
    "dictionary = corpora.Dictionary(tokenized)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized]\n",
    "print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.001*\"httpstco7aua0xky6l\" + 0.001*\"nidlpgeek\" + 0.001*\"of\"'), (1, u'0.001*\"nouvelle\" + 0.001*\"blackwidow\" + 0.001*\"foi\"'), (2, u'0.001*\"httpstco67dabpjj8j\" + 0.001*\"you\" + 0.001*\"rewatching\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results With Frequent Words In Twitter Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = dt['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "#print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'monday', u'king', u'blackpanther', u'avengersinfinitywar', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "#Stop-word Removal for frequent words\n",
    "sws = set(stopwords.words('english'))\n",
    "sws.add('rt') # Tweet specific stop-words\n",
    "sws.add('wakanda')\n",
    "sws.add('avengers')\n",
    "sws.add('marvel')\n",
    "sws_removed = []\n",
    "for j,sent in enumerate(tokenized):\n",
    "    sws_removed.append([i for i in sent if i not in sws])\n",
    "print(sws_removed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sws_removed)\n",
    "corpus = [dictionary.doc2bow(text) for text in sws_removed]\n",
    "#print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.076*\"\\u2026\" + 0.075*\"blackpanther\" + 0.046*\"liked\" + 0.046*\"man\"'), (1, u'0.042*\"\\udd17\" + 0.042*\"\\ud83e\" + 0.036*\"de\" + 0.033*\"\\ud83d\"'), (2, u'0.062*\"spot\" + 0.044*\"infinity\" + 0.044*\"war\" + 0.041*\"de\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3, num_words=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punctutation Removal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = dt['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'!', u'the', u'king', u'is', u'here', u'!', u'#blackpanther', u'#avengersinfinitywar', u'#wakanda', u'forever', u'https://t.co/syvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "#Do not include punctuation removal\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens)]).split())\n",
    "print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'!', u'king', u'!', u'#blackpanther', u'#avengersinfinitywar', u'#wakanda', u'forever', u'https://t.co/syvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "sws = set(stopwords.words('english'))\n",
    "sws.add('rt') # Tweet specific stop-words\n",
    "sws_removed = []\n",
    "for j,sent in enumerate(tokenized):\n",
    "    sws_removed.append([i for i in sent if i not in sws])\n",
    "print(sws_removed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sws_removed)\n",
    "corpus = [dictionary.doc2bow(text) for text in sws_removed]\n",
    "#print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.091*\":\" + 0.044*\".\" + 0.044*\",\"'), (1, u'0.080*\"photo\" + 0.078*\"@jackfluck\" + 0.060*\"#marvel\"'), (2, u'0.051*\":\" + 0.050*\"war\" + 0.050*\"infinity\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Stemming Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = dt['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'the', u'king', u'is', u'here', u'blackpanther', u'avengersinfinitywar', u'wakanda', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation)\n",
    "tokenized = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in all_docs:\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    tokenized.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "print(tokenized[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'marvel', u'monday', u'king', u'blackpanther', u'avengersinfinitywar', u'wakanda', u'forever', u'httpstcosyvcvl2ztv']\n"
     ]
    }
   ],
   "source": [
    "#Stop-word Removal for frequent words\n",
    "sws = set(stopwords.words('english'))\n",
    "sws.add('rt') # Tweet specific stop-words\n",
    "sws_removed = []\n",
    "for j,sent in enumerate(tokenized):\n",
    "    sws_removed.append([i for i in sent if i not in sws])\n",
    "print(sws_removed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marvel monday ! the king is here ! # blackpanth # avengersinfinitywar # wakanda forev http : //t.co/syvcvl2ztv\n"
     ]
    }
   ],
   "source": [
    "#Word-stemming\n",
    "ps = PorterStemmer()\n",
    "stemmed = []\n",
    "\n",
    "for doc in all_docs: \n",
    "    sentence = word_tokenize(doc.lower())\n",
    "    stems = (' '.join([ps.stem(tokenized) for tokenized in sentence]))\n",
    "    stemmed.append(stems)\n",
    "\n",
    "print(stemmed[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sws_removed)\n",
    "corpus = [dictionary.doc2bow(token) for token in sws_removed]\n",
    "#print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.067*\"avengers\" + 0.062*\"\\u2026\" + 0.054*\"marvel\"'), (1, u'0.050*\"wakanda\" + 0.036*\"avengers\" + 0.036*\"war\"'), (2, u'0.064*\"avengers\" + 0.053*\"wakanda\" + 0.043*\"de\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
